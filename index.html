<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Differentially Private Gaussian Processes</title>

		<meta name="description" content="Differentially Private Gaussian Processes">
		<meta name="author" content="Mike Smith">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css" id="theme">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides" data-background="assets/pres_bg.png">
				<section data-background="assets/pres_bg.png">
                    
					<h3>Differentially Private<br/> Gaussian Processes</h3>
					<p>
						<small>Presented by Mike Smith</small><br/>
                        <small><a href="mailto:m.t.smith@sheffield.ac.uk">m.t.smith@sheffield.ac.uk</a></small>
					</p>
				</section>

				<section>
					<h2>Differential Privacy</h2><h3>A Quick Introduction</h3>
					<p>See <a href="https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf">The Algorithmic Foundations of Differential Privacy</a> by Dwork and Roth for a rigorous introduction to the framework.
					</p>
				</section>

				<section data-background="assets/pres_bg.png">
					<h2>Anonymity Gone Wrong</h2>
					<p>
						In the mid-1990s the Massachusetts Group Insurance Commission released 'anonymised' health records for state employees.

					</p>
                    <img src="assets/mutual.jpg" width="50%" />
				</section>

                <section data-background="assets/pres_bg.png">
					<h2>Anonymity Gone Wrong</h2>
					<p>
                        <img src="assets/weld.jpg" width="50%" align="right" style="margin:50px;" />
                        The Governor assured the public that GIC had protected patient privacy by deleting identifiers.<br/> <small><a href="https://epic.org/privacy/reidentification/ohm_article.pdf">Broken Promises of Privacy, Paul Ohm</a></small>
					</p>

				</section>
                <section data-background="assets/pres_bg.png">
					<h2>Anonymity Gone Wrong</h2>
					<p>
                        The data was 'anonymised' by removing names. Other identifying columns remained.
                        <img src="assets/example.png" style="margin:50px;" />
					</p>

				</section>

               <section data-background="assets/pres_bg.png">
					<h2>Anonymity Gone Wrong</h2>
					<p>
                        <img src="assets/sweeney.jpg" align="right" style="margin:50px;" />
                        Latanya Sweeney used the voter rolls to find the Governor's medical records...</p>
                    <p><span class="fragment">...which she posted to him.</span>
                    <p style="color:#eec; text-align:left;"><span class="fragment">This is a <b>linkage attack</b>:
                    it uses <b>auxiliary information</b> to compromise privacy in a database.</span></p>
					</p>
				</section>

                


                <section data-background="assets/pres_bg.png">
					<h2>Example</h2>   
                    <p>We might want to find out whether people hold a controversial view, that they wouldn't normally express:</p> 
                    <h3 style="color:#bbf;">The trams were actually a good idea</h3>
                    <p>Many people in this room might secretly agree, but maybe wouldn't like to say 'Yes' to this question.</p>      

				</section>




                <section data-background="assets/pres_bg.png">					
                    <img src="assets/coinflip1.png"/>
				</section>

                <section data-background="assets/pres_bg.png">
                    <span><img src="assets/coinflip1.png" width=25% align="right" style="margin-bottom:100%"/>
If flips are different, tell the truth.</p> <p class="fragment">If they're the same...</p> <span class="fragment"><p>say</p><p>YES for heads</p><span class="fragment"><p>and</p><p> NO for tails</span>
				</section>


<section>
<small>
<table><tr><td></td><th>0</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>10</th><th>11</th><th>12</th><th>13</th><th>14</th><th>15</th><th>16</th><th>17</th><th>18</th><th>19</th></tr><tr><th>0</th><td>50</td><td>38</td><td>27</td><td>19</td><td>13</td><td>9</td><td>6</td><td>4</td><td>3</td><td>2</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><th>1</th><td>63</td><td>50</td><td>38</td><td>28</td><td>20</td><td>14</td><td>10</td><td>7</td><td>4</td><td>3</td><td>2</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><th>2</th><td>73</td><td>62</td><td>50</td><td>39</td><td>29</td><td>21</td><td>15</td><td>11</td><td>7</td><td>5</td><td>3</td><td>2</td><td>2</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><th>3</th><td>81</td><td>72</td><td>62</td><td>50</td><td>40</td><td>30</td><td>22</td><td>16</td><td>11</td><td>8</td><td>6</td><td>4</td><td>3</td><td>2</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>
<tr><th>4</th><td>87</td><td>80</td><td>72</td><td>61</td><td>50</td><td>40</td><td>31</td><td>23</td><td>17</td><td>12</td><td>9</td><td>6</td><td>4</td><td>3</td><td>2</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td></tr>
<tr><th>5</th><td>91</td><td>86</td><td>79</td><td>71</td><td>61</td><td>51</td><td>41</td><td>32</td><td>24</td><td>18</td><td>13</td><td>10</td><td>7</td><td>5</td><td>3</td><td>2</td><td>2</td><td>1</td><td>1</td><td>1</td></tr>
<tr><th>6</th><td>94</td><td>91</td><td>85</td><td>79</td><td>70</td><td>61</td><td>51</td><td>41</td><td>32</td><td>25</td><td>19</td><td>14</td><td>10</td><td>8</td><td>5</td><td>4</td><td>3</td><td>2</td><td>1</td><td>1</td></tr>
<tr><th>7</th><td>96</td><td>94</td><td>90</td><td>85</td><td>78</td><td>69</td><td>60</td><td>51</td><td>42</td><td>33</td><td>26</td><td>20</td><td>15</td><td>11</td><td>8</td><td>6</td><td>4</td><td>3</td><td>2</td><td>2</td></tr>
<tr><th>8</th><td>97</td><td>96</td><td>93</td><td>89</td><td>84</td><td>77</td><td>69</td><td>60</td><td>51</td><td>42</td><td>34</td><td>27</td><td>21</td><td>16</td><td>12</td><td>9</td><td>7</td><td>5</td><td>3</td><td>3</td></tr>
<tr><th>9</th><td>98</td><td>97</td><td>95</td><td>92</td><td>88</td><td>83</td><td>76</td><td>68</td><td>60</td><td>51</td><td>42</td><td>35</td><td>28</td><td>22</td><td>17</td><td>13</td><td>10</td><td>7</td><td>5</td><td>4</td></tr>
<tr><th>10</th><td>99</td><td>98</td><td>97</td><td>95</td><td>92</td><td>87</td><td>82</td><td>75</td><td>68</td><td>59</td><td>51</td><td>43</td><td>35</td><td>28</td><td>23</td><td>18</td><td>14</td><td>10</td><td>8</td><td>6</td></tr>
<tr><th>11</th><td>99</td><td>99</td><td>98</td><td>96</td><td>94</td><td>91</td><td>87</td><td>81</td><td>75</td><td>67</td><td>59</td><td>51</td><td>43</td><td>36</td><td>29</td><td>23</td><td>18</td><td>14</td><td>11</td><td>8</td></tr>
<tr><th>12</th><td>99</td><td>99</td><td>98</td><td>97</td><td>96</td><td>94</td><td>90</td><td>86</td><td>80</td><td>74</td><td>67</td><td>59</td><td>51</td><td>43</td><td>36</td><td>30</td><td>24</td><td>19</td><td>15</td><td>12</td></tr>
<tr><th>13</th><td>100</td><td>99</td><td>99</td><td>98</td><td>97</td><td>95</td><td>93</td><td>90</td><td>85</td><td>80</td><td>73</td><td>66</td><td>59</td><td>51</td><td>44</td><td>37</td><td>30</td><td>25</td><td>20</td><td>16</td></tr>
<tr><th>14</th><td>100</td><td>100</td><td>99</td><td>99</td><td>98</td><td>97</td><td>95</td><td>92</td><td>89</td><td>84</td><td>79</td><td>73</td><td>66</td><td>58</td><td>51</td><td>44</td><td>37</td><td>31</td><td>25</td><td>21</td></tr>
<tr><th>15</th><td>100</td><td>100</td><td>100</td><td>99</td><td>99</td><td>98</td><td>96</td><td>94</td><td>92</td><td>88</td><td>84</td><td>78</td><td>72</td><td>65</td><td>58</td><td>51</td><td>44</td><td>38</td><td>32</td><td>26</td></tr>
<tr><th>16</th><td>100</td><td>100</td><td>100</td><td>99</td><td>99</td><td>98</td><td>97</td><td>96</td><td>94</td><td>91</td><td>87</td><td>83</td><td>78</td><td>71</td><td>65</td><td>58</td><td>51</td><td>44</td><td>38</td><td>32</td></tr>
<tr><th>17</th><td>100</td><td>100</td><td>100</td><td>100</td><td>99</td><td>99</td><td>98</td><td>97</td><td>96</td><td>93</td><td>91</td><td>87</td><td>82</td><td>77</td><td>71</td><td>65</td><td>58</td><td>51</td><td>45</td><td>38</td></tr>
<tr><th>18</th><td>100</td><td>100</td><td>100</td><td>100</td><td>100</td><td>99</td><td>99</td><td>98</td><td>97</td><td>95</td><td>93</td><td>90</td><td>86</td><td>82</td><td>76</td><td>71</td><td>64</td><td>58</td><td>51</td><td>45</td></tr>
<tr><th>19</th><td>100</td><td>100</td><td>100</td><td>100</td><td>100</td><td>99</td><td>99</td><td>99</td><td>98</td><td>97</td><td>95</td><td>92</td><td>89</td><td>86</td><td>81</td><td>76</td><td>70</td><td>64</td><td>58</td><td>51</td></tr>
</table>
</small>
</section>

<section data-background="assets/pres_bg.png">
					<h2>Summary</h2>
					<p>We want to protect a user from a linkage attack...</p>
                    <p class="fragment">...while still performing inference over the whole group.</p>
                    <p class="fragment">Making a dataset private needs more than just erasing names.</p>             
                    <p class="fragment">To achieve a level of privacy one needs to add <b>randomness</b> to the data.</p>
                    <p class="fragment">This is a fundamental feature of differential privacy.</p>
				</section>
				
<section data-background="assets/pres_bg_bb.png" data-markdown>
<script type="text/template">
<h2>Differential Privacy</h2>
<p>A randomised algorithm $M$ is $\varepsilon$-differentially private if, for all $m$, and for all neighbouring databases $D_1$ and $D_2$</p>
<p>$P\Big( M(D_1) = m \Big) \leq e^{\varepsilon} P\Big( M(D_2) = m \Big)$
<img src="assets/dp_graph.png" width=55%></p>
</script>
</section>

<section data-background="assets/pres_bg_bb.png" data-markdown>
<script type="text/template">
<p>The coin flip mechanism is $(\ln 3)$-differentially private.</p>
</script>
</section>

<section data-background="assets/pres_bg_bb.png" data-markdown>
<script type="text/template">
<h2>Counting Queries</h2>
<p>How many people have diabetes?</p>
<img src="assets/db0.png">
<p>We'll call this database $D_1$.</p>
<p>Our query function, $M$, is noisy summation.</p>
</script>
</section>

<section data-background="assets/pres_bg_bb.png" data-markdown>
<script type="text/template">
<p>How many people have diabetes?</p>
<img src="assets/db.png">
<p>We'll call this database $D_2$.</p>
</script>
</section>

<section data-background="assets/pres_bg_bb.png" data-markdown>
<script type="text/template">
<p>
If the actual output value $m = 4$, what is the probability of that output, for the two databases?
<img src="assets/laplace3.png" style="border:none;" />
</p>
</script>
</section>

<section data-background="assets/pres_bg.png">
	<h2>Differential Privacy for GPs</h2>
</section>

<section data-background="assets/pres_bg.png">
	<h3>Differential Privacy for GPs</h3>
	<p>We have a dataset in which the inputs, $X$, are <b>public</b>. The outputs, $\mathbf{y}$, we want to keep <b>private</b>.</p>
    <img src="assets/kung_simple.png" width="75%" style="margin:0px; border:none;" />
    <p style="font-size:small;"><b>Data consists of the heights and weights of 287 women from a census of the !Kung</b></p>
</section>


<section data-background="assets/pres_bg.png">
	<h3>Vectors and Functions</h3>
	<p>Hall et al. (2013) showed that one can ensure that a version
of $f$, function $\tilde{f}$ is $(\varepsilon, \delta)$-differentially private by adding a scaled sample from a GP prior.</p>
<img src="assets/hall1.png" width="40%" style="margin:0px; border:none;" />
</section>

<section data-background="assets/pres_bg.png">
	<h3>Applied to GPs</h3>
	<p>We applied this method to the GP posterior.</p>
	<p class="fragment">The covariance of the posterior only depends on the inputs, $X$. So we can compute this without applying DP.</p>
	<p class="fragment">The mean function, $f_D(\mathbf{x_*})$, does depend on $\mathbf{y}$.
	$f_D(\mathbf{x_*}) = \mathbf{k}_*^\top K^{-1} \mathbf{y}$</p>
	<p class="fragment">We are interested in finding $|| f_D(\mathbf{x_*}) - f_{D^\prime}(\mathbf{x_*}) ||_H^2$</p>
	<p class="fragment">...how much the mean function (in RKHS) can change due to a change in $\mathbf{y}$.</p>
</section>

<section data-background="assets/pres_bg.png">
	<h3>Applied to GPs</h3>
	<p>Using the representer theorem, we can write $|| f_D(\mathbf{x_*}) - f_{D^\prime}(\mathbf{x_*}) ||_H^2$<br/> as:</p>
	<p>$\Big|\Big|\sum_{i=1}^n k(\mathbf{x_*},\mathbf{x}_i) \left(\alpha_i - \alpha^\prime_i\right)\Big|\Big|_H^2$</p>
	<p>where $\mathbf{\alpha} - \mathbf{\alpha}^\prime = K^{-1} \left(\mathbf{y} - \mathbf{y}^\prime \right)$</p>	
</section>

<section data-background="assets/pres_bg.png">
    <p>$\Big|\Big|\sum_{i=1}^n k(\mathbf{x_*},\mathbf{x}_i) \left(\alpha_i - \alpha^\prime_i\right)\Big|\Big|_H^2$</p>
	<p>where $\mathbf{\alpha} - \mathbf{\alpha}^\prime = K^{-1} \left(\mathbf{y} - \mathbf{y}^\prime \right)$</p>
	<p class="fragment">We constrain the kernel: $-1\leq k \leq 1$ and we only allow one element of $\mathbf{y}$ and $\mathbf{y}'$ to differ (by at most $d$).</p>
	<p class="fragment">So only one column of $K^{-1}$ will be involved in the change of mean (which we are summing over).</p>
	<p class="fragment">The distance above can then be shown to be no greater than $d\;||K^{-1}||_\infty$	
</section>

<section data-background="assets/pres_bg.png">
    <h3>Applied to GPs</h3>
    <p>This 'works' in that it allows DP predictions...</p>
    <p>But to avoid too much noise, the value of $\varepsilon$ is too large (here it is 100!)</p>
    <img src="assets/kung_standard_simple.png" width="75%" style="margin:0px; border:none;" />
</section>

<section data-background="assets/pres_bg.png">
    <h3>Inducing Inputs</h3>
    <p>Using sparse methods (i.e. inducing inputs) can help reduce the sensitivity a little.</p>
    <img src="assets/kung_pseudo_simple.png" width="75%" style="margin:0px; border:none;" />
</section>

<section data-background="assets/pres_bg.png">
    <h3>Effect of perturbation</h3>
    <p>Previously I mentioned that the noise is sampled from the GP's <b>prior</b>.</p>
    <p>This is not necessarily the most 'efficient' covariance to use.</p>
    <img src="assets/cloak1.png" width="75%" style="margin:0px; border:none;" />
</section>

<section data-background="assets/pres_bg.png">
    <h3>Effect of perturbation</h3>
    <img src="assets/cloak2.png" width="75%" style="margin:0px; border:none;" />
</section>

<section data-background="assets/pres_bg.png">
    <h3>Cloaking</h3>
    <p>Left: Ideal covariance. Right: actual covariance</p>
    <img src="assets/cloak3.png" width="75%" style="margin:0px; border:none;" />
</section>

<section data-background="assets/pres_bg.png">
    <h3>Cloaking</h3>
    <p>Hall et al. (2013) also presented a bound on vectors.</p>
    <p>We need to find a bound ($\Delta$) on the scale of the output change, in term of its Mahalanobis distance with respect to the added noise covariance.</p>
    <p>$\sup_{D \sim {D'}} ||M^{-1/2} (\mathbf{y}_D - \mathbf{y}_{D'})||_2 \leq \Delta$</p>
    <p>Then use this to add noise to our vector $\mathbf{v}_D$:</p>
    <p>$\tilde{\mathbf{v}_D} = \mathbf{v}_D + \frac{\text{c}(\delta)\Delta}{\varepsilon}Z$</p>
</section>

<section data-background="assets/pres_bg.png">
    <h3>Cloaking</h3>
    <p>Intuitively we want to construct M so that it has greatest covariance in those directions most affected by changes in training points, so that it will be most able to mask those changes.</p>
    <p>The posterior mean predictions are,</p>
    <p>$\mathbf{y}_* = K_{*f} K^{-1} \mathbf{y}$</p>
    <p>The effect of perturbing each training point on each test point is represented in the cloaking matrix, $C = K_{*f} K^{-1}$
</section>

<section data-background="assets/pres_bg.png">
    <h3>Cloaking</h3>
    <p>We assume we only need protect the change in one training input at a time.</p>
    <p>...introduce y-y' earlier</p>
    <p>sub into bound</p>
    <p>optimisation</p>
    <p>Example: House prices</p>
    <p>Example: citibike</p>
    <p>Also need to do intro re uganda</p>
</section>

<section data-background="assets/pres_bg.png">
<small>
<p align="left">
<span style='margin-left:-50px;'><b>The go-to book on differential privacy, by Dwork and Roth;</b><br/></span>
Dwork, Cynthia, and Aaron Roth. "The algorithmic foundations of differential privacy." Theoretical Computer Science 9.3-4 (2013): 211-407.
<a href="https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf">link</a>
</p>
<p align="left">
<span style='margin-left:-50px;'><b>I found this paper allowed me to start applying DP to GP;</b><br/></span>
Hall, Rob, Alessandro Rinaldo, and Larry Wasserman. "Differential privacy for functions and functional data." The Journal of Machine Learning Research 14.1 (2013): 703-727.
<a href="http://www.stat.cmu.edu/~arinaldo/papers/hall13a.pdf">link</a>
</p>

<p align="left">
<span style='margin-left:-50px;'><b>Articles about the Massachusetts privacy debate</b><br/></span>
Barth-Jones, Daniel C. "The're-identification'of Governor William Weld's medical information: a critical re-examination of health data identification risks and privacy protections, then and now." Then and Now (June 4, 2012) (2012).  <a href="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2076397">link</a>
</p>
<p align="left">
Ohm, Paul. "Broken promises of privacy: Responding to the surprising failure of anonymization." UCLA Law Review 57 (2010): 1701. <a href="https://epic.org/privacy/reidentification/ohm_article.pdf">link</a>
</p>

<p align="left">Narayanan, Arvind, and Edward W. Felten. "No silver bullet: De-identification still doesn’t work." White Paper (2014). <a href="http://randomwalker.info/publications/no-silver-bullet-de-identification.pdf">link</a></p>

<p>Howell, N. Data from a partial census of the !kung san,
dobe. 1967-1969. https://public.tableau.
com/profile/john.marriott#!/vizhome/
kung-san/Attributes, 1967.</p>

<p align="left"><span style='margin-left:-50px;'><b>Images used:</b></span>
BostonGlobe: <a href="https://c.o0bg.com/rf/image_960w/Boston/2011-2020/2015/05/29/BostonGlobe.com/Business/Images/MassMutual_04.jpg">Mass Mutual</a>, 
 <a href="https://c.o0bg.com/rf/image_960w/Boston/2011-2020/2014/10/20/BostonGlobe.com/Metro/Images/Gov.%20Bill%20Weld%201-100425.jpg">Weld</a>. Harvard: <a href="http://www.gov.harvard.edu/files/Sweeney6crop.jpg">Sweeney</a>. Rich on flickr: <a href="https://www.flickr.com/photos/rich_b1982/13114665103/in/pool-sheffieldskyline/">Sheffield skyline</a>.</p>
<p>
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
</p>
</small>
</section>


</div>

</div>

<script src="lib/js/head.min.js"></script>
<script src="js/reveal.js"></script>

<script>

	// Full list of configuration options available at:
	// https://github.com/hakimel/reveal.js#configuration
	Reveal.initialize({
		controls: true,
		progress: true,
		history: true,
		center: true,

        math: {
            mathjax: 'https://cdn.mathjax.org/mathjax/latest/MathJax.js',
            config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
        },

		transition: 'slide', // none/fade/slide/convex/concave/zoom

		// Optional reveal.js plugins
		dependencies: [
			{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
			{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
			{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
			{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
			{ src: 'plugin/zoom-js/zoom.js', async: true },
			{ src: 'plugin/notes/notes.js', async: true },
            { src: 'plugin/math/math.js', async: true }
		]
	});

</script>

</body>
</html>
